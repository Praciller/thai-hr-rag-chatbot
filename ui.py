import streamlit as st
import os
from dotenv import load_dotenv

from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.prompts import PromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser
from langchain_community.document_loaders import DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# ‡πÇ‡∏´‡∏•‡∏î API Key ‡∏à‡∏≤‡∏Å Secrets ‡∏Ç‡∏≠‡∏á Streamlit ‡∏´‡∏£‡∏∑‡∏≠ .env ‡πÑ‡∏ü‡∏•‡πå
load_dotenv()

DATA_PATH = "data"
DB_PATH = "db"

# --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ RAG Chain ---

def setup_vector_database():
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ Vector DB ‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡πÉ‡∏´‡∏°‡πà
    """
    if not os.path.exists(DB_PATH):
        st.write("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Vector DB, ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡πÉ‡∏´‡∏°‡πà...")
        # 1. ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
        loader = DirectoryLoader(DATA_PATH, glob="*.txt")
        documents = loader.load()
        # 2. ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        texts = text_splitter.split_documents(documents)
        # 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á Embeddings ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö
        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
        vector_store = Chroma.from_documents(
            documents=texts, 
            embedding=embeddings, 
            persist_directory=DB_PATH
        )
        st.write("‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Vector DB ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
    else:
        st.write("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Vector DB ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà...")

@st.cache_resource
def load_rag_chain():
    """
    ‡πÇ‡∏´‡∏•‡∏î RAG Chain ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏ó‡∏≥‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÅ‡∏•‡∏∞ cache ‡πÑ‡∏ß‡πâ)
    """
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á DB ‡∏Å‡πà‡∏≠‡∏ô
    setup_vector_database()

    # 1. ‡πÇ‡∏´‡∏•‡∏î LLM
    llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash-latest", temperature=0)
    # 2. ‡πÇ‡∏´‡∏•‡∏î Vector Store
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    vector_store = Chroma(persist_directory=DB_PATH, embedding_function=embeddings)
    retriever = vector_store.as_retriever()
    # 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt
    template = """
    ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏Ç‡∏≠‡∏á‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó AI ‡∏™‡∏¢‡∏≤‡∏° ‡∏à‡∏≥‡∏Å‡∏±‡∏î ‡∏°‡∏µ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
    ‡πÇ‡∏õ‡∏£‡∏î‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å '‡∏ö‡∏£‡∏¥‡∏ö‡∏ó' ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡∏´‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ "‡∏â‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà"
    ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó: {context}
    ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}
    ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:
    """
    prompt = PromptTemplate.from_template(template)
    # 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á Chain
    chain = (
        {"context": retriever, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )
    return chain

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö (Streamlit UI) ---

st.title("ü§ñ ‡∏£‡∏∞‡∏ö‡∏ö‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• HR")
st.header("‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó AI ‡∏™‡∏¢‡∏≤‡∏° ‡∏à‡∏≥‡∏Å‡∏±‡∏î")

try:
    rag_chain = load_rag_chain()
    user_question = st.text_input("‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà:")
    if user_question:
        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö..."):
            answer = rag_chain.invoke(user_question)
            st.write("### ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:")
            st.markdown(answer)
except Exception as e:
    st.error("‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô:")
    st.error(e)